{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ms_feature_validation as mfv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Metabolomics data\n",
    "\n",
    "Metabolomics data is stored in a DataContainer Object. Data container can be built using pandas DataFrame or read directly from output files from common tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from a Progenesis csv file\n",
    "fname = \"SuerosRCC_ESi_neg_default_SepOct2017.csv\"\n",
    "data = mfv.filter.read_progenesis(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data container stores infromation in three different DataFrames:\n",
    "\n",
    "1. Data Matrix: contains feature values for each sample. Each sample is a row and each feature is a column.\n",
    "2. Sample Metadata: contains sample information, such as class, run order, batch, sample id, etc... Each sample.\n",
    "3. Feature Metadata: contains feature information. In the case of LC-MS data it contains retention time, exact mass, etc... Each row is a feature.\n",
    "\n",
    "Index are shared between data matrix rows and sample metadata rows, and between data matrix columns and feature metadata rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.feature_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some common fields such as class, run order, batch number are accessible as DataContainer attributes. Run order and batch will raise an Exception if they are not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting run order information and batch information\n",
    "\n",
    "order and batch can be set as attributes of the DataContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, the sample name contains batch and order information.\n",
    "# This code extracts this info from the sample name and set up the bath and order attributes\n",
    "\n",
    "# index have the following format: name_date_project_run_order\n",
    "# date is obtained and converted to a batch number\n",
    "# extracting batch data\n",
    "batch = pd.Series(data=data.sample_metadata.index.str.split(\"_\"), index=data.data_matrix.index)\n",
    "batch = batch.apply(lambda x: x[1])\n",
    "days = np.sort(batch.unique())\n",
    "batch_map = dict(zip(days, np.arange(1, days.size + 1)))\n",
    "batch = batch.map(batch_map)\n",
    "# extracting order data\n",
    "order = pd.Series(data=data.sample_metadata.index.str.split(\"_\"), index=data.data_matrix.index)\n",
    "order = order.apply(lambda x: x[-1]).astype(int)\n",
    "\n",
    "data.order = order\n",
    "data.batch = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data curation\n",
    "\n",
    "Data curation is implementated through a series of Process objects that perform transformations on the Data matrix or remove features/samples according to a criteria. Data curation is strongly based on concepts defined on [this paper](https://doi.org/10.1007).\n",
    "\n",
    "Even if the filters are highly customizable, the easiest way to perform data curation is first to define a mapping.\n",
    "A mapping is a dictionary that maps sample types to sample classes. Using the information provided by a mapping, a Processor knows which sample to use to correct a data set and which classes are to be corrected.\n",
    "\n",
    "Once created, a filter is used with the method process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this example we define the Quality control samples as samples of the class QC,\n",
    "# blank samples as samples of the class \"SV\" and sample types as samples of the class EI, EII, EIII and EIV\n",
    "data.mapping\n",
    "mapping = {\"blank\": [\"SV\"],\n",
    "           \"qc\": [\"QC\"],\n",
    "           \"sample\": [\"EI\", \"EII\", \"EIII\", \"EIV\", \"CS\"]}\n",
    "data.mapping = mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting common metrics from DataContainer objects\n",
    "\n",
    "Some common metrics associated with metabolomics data can be obtained using the metrics object:\n",
    "\n",
    "1. CV for each feature\n",
    "2. D-Ratio for each feature\n",
    "3. Detection rate for each feature\n",
    "4. PCA loadings, scores and cumulative variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv for each class\n",
    "cv = data.metrics.cv()\n",
    "cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, loading, variance = data.metrics.pca(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(12, 8))\n",
    "sns.scatterplot(data=score, x=\"PC1\", y=\"PC2\", hue=data.classes, ax=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank correction\n",
    "br = mfv.filter.BlankCorrector(mode=\"lod\")\n",
    "br.process(data)\n",
    "\n",
    "# prevalence filter\n",
    "pf = mfv.filter.PrevalenceFilter()\n",
    "pf.process(data)\n",
    "\n",
    "# variation filter\n",
    "vf = mfv.filter.VariationFilter()\n",
    "vf.process(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several filters can be applied using the Pipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert filter effects\n",
    "data.reset()\n",
    "\n",
    "# process data with several filters using a pipeline\n",
    "pipe = mfv.filter.Pipeline([br, pf, vf])\n",
    "pipe.process(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizing raw LC-MS data\n",
    "\n",
    "Raw MS data in the mzML format can be read using the pyopenms module. Several functions are incorporated in the MSData object to read and process MS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ms_feature_validation as mfv\n",
    "lcms_data = mfv.fileio.MSData(\"20190918_039.mzML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making EIC for a list of mz\n",
    "mz_list = [203.0821, 508.3403, 285.2066]\n",
    "rt, eic = lcms_data.get_eic(mz_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(rt, eic[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfv.peaks.pick_cwt(rt, eic[1, :], min_width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(rt).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
